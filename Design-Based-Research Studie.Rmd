---
output:  
   html_document:
      css: Style/custom.css
bibliography: ../../../../../../Downloads/library.bib
csl: Bib/dgps.csl
---

```{r fb_data and log_data reading, cache = T, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
library(readr)
library(tidyverse)
## Import sus_fb_data
sus_fb_data <- read_delim("data/sus_fb_data_abiturma_fr16.csv", ";")

## Import kl_fb_data
kl_fb_data <- read_delim("data/kl_fb_data_abiturma_fr16_ohne_labels.csv", "|", escape_double = TRUE )

### Import der jitter logfiles
files_jitter      <- list.files("data/logdata/rawdata_17/responses_jitter",   full.names = T)
files_likert_1    <- list.files("data/logdata/rawdata_17/responses_likert",   full.names = T)
files_likert_2    <- list.files("data/logdata/rawdata_18/responses_likert",   full.names = T)
files_dropdown    <- list.files("data/logdata/rawdata_18/responses_qualdim2", full.names = T)
files_freitexte_1 <- list.files("data/logdata/rawdata_17/responses_freitext", full.names = T)
files_freitexte_2 <- list.files("data/logdata/rawdata_18/responses_freitext", full.names = T)

log_files <- c(files_jitter,    
               files_likert_1,   
               files_likert_2,   
               files_dropdown,   
               files_freitexte_1,
               files_freitexte_2)

## Reading and Merging jitter logs
for (file in log_files){
  
  # if the merged dataset doesn't exist, create it
  if (!exists("log_data_raw")){
    log_data_raw <- read_delim(file, ",", col_types = cols(.default = col_character()))
  }
  
  # if the merged dataset does exist, append to it
  if (exists("log_data_raw")){
    temp_dataset <-read_delim(file, ",", col_types = cols(.default = col_character()))
    log_data_raw <- merge(log_data_raw, temp_dataset, all = T)
    rm(temp_dataset)
  }
}
```

```{r logdatawrangling2, echo=F, results="hide", warning=F, message=F}
library(tidyverse)
log_data <- log_data_raw[grepl("[@]", log_data_raw$user), ] ## Filtern der Zeilen mit Kommata 
log_data <- log_data%>%                                     ## in IP-Adresse
  mutate(user = factor(user),
         systtime = lubridate::ymd_hms(systtime))%>%
  tbl_df()%>%
  filter(systtime > lubridate::ymd_hms("2016-06-30 18-00-00"))%>%  ## Test-Logins vor Release-Time filtern
  group_by(user)%>%                                                      ##
  arrange(desc(systtime))%>%                                             ## Berechnung der Verweildauern
  mutate(v_dauer = as.numeric(c(NA, -1*diff(systtime))),                 ## 
         v_dauer_t = ifelse(is.na(v_dauer) == T, NA,                     ## 
                       ifelse(v_dauer <= 0, NA,                          ## 
                              ifelse(v_dauer > 650, NA, v_dauer))))%>%  ## 
  ungroup()%>%                                                           ##
  arrange(user,systtime) 

  # View(select(log_data, user, systtime, v_dauer, v_dauer_t))         ## Unsystematische Validierung der Verweildauer

scale_this <- function(x){                                ## wegen Problemen von `scale()` in `mutate()`
  (x - mean(x, na.rm=TRUE)) / sd(x, na.rm=TRUE)
}

log_data_fplot <- log_data%>%                                   
  mutate(Inferenzniveau = ifelse(is.na(sort_freitexte) == F, "Freitexte",                              ## Umbenennung &
                                 ifelse(is.na(likertfragen) == F, "Einzelitems",                       ## Recoding
                                        "Qualitätsdimensionen")),                               
        `Anz. Klicks` = 1,
         boxplot = ifelse(grepl("box", darstell), "boxplot", NA),
        `arith. Mittel`     = ifelse(grepl("mean", darstell), "arith. Mittel", NA),
         Konfindezintervall = ifelse(grepl("-ci-", darstell), "Konfindezintervall", NA),
         Einzelwerte        = ifelse(grepl("jitter", darstell), "Einzelwerte", NA),
         Qualitätsdimension = likertfragen,
         Leitfragen         = ifelse(qualdim2 == "ueber", "Überblick",
                                     ifelse(qualdim2 == "gmean", "sozialer Vergleich",
                                            ifelse(qualdim2 == "staerken", "ipsativer Vergleich",
                                                   ifelse(qualdim2 == "kurse", "Vergl. zw. eigenen Gruppen",NA)))),
        `Skalierung Einzelfr.`     = ifelse(groupinl == "gmean", "sozialer Vergleich", 
                                            ifelse(groupinl != "gmean" & is.na(likertfragen) == F, "kein Vergleich", NA)),
        `Skalierung Qualitätsdim.` = ifelse(scaling == "std", "sozialer Vergleich",
                                           ifelse(scaling == "raw", "Likertskala",
                                                  ifelse(scaling == "gstd", "ipsativer Vergleich", NA))))%>%
  gather(Kennwerte_i, Kennwerte, boxplot , `arith. Mittel`, Konfindezintervall, Einzelwerte)%>%
  mutate(Kennwerte = as.factor(Kennwerte))
  


## Export Log_data_long
 #feather::write_feather(select(log_data_fplot, Inferenzniveau, Kennwerte, 
 #                              Qualitätsdimension, Leitfragen, 
 #                              `Skalierung Einzelfr.`, `Skalierung Qualitätsdim.`, v_dauer_t, 
 #                              v_dauer_gm, v_dauer_t_gm, v_dauer_ip, 
 #                              v_dauer_t_ip, Klick), "shiny/log_data_fplot.feather")
 
## Log_data je Person generieren 
 log_data_short <- log_data_fplot%>%
   select(Inferenzniveau, Kennwerte, Qualitätsdimension, Leitfragen, user,
          `Skalierung Einzelfr.`, `Skalierung Qualitätsdim.`, v_dauer_t, `Anz. Klicks`)%>%
   gather(variable, value, -user, -v_dauer_t, -`Anz. Klicks`)%>%
   na.omit()%>%
   group_by(user, variable, value)%>%
   summarize(v_dauer_t_pp = sum(v_dauer_t, na.rm = T),
             Summe_Klicks = sum(`Anz. Klicks`))%>%
   ungroup()%>%
   group_by(variable)%>%
   mutate(v_dauer_t_pp_gm = scale_this(v_dauer_t_pp),
          Summe_Klicks_gm = scale_this(Summe_Klicks))%>%
   ungroup()%>%
   group_by(user)%>%
   mutate(v_dauer_t_pp_ip = scale_this(v_dauer_t_pp),
          Summe_Klicks_ip = scale_this(Summe_Klicks))%>%
   ungroup()%>%
   filter(value != "nolikert")
 
 ## Export
 readr::write_csv(log_data_short, "shiny/log_data_short.csv")
 feather::write_feather(log_data_short, "shiny/log_data_short.feather")
 
 
 
 
 ## Aufbereitung der Selbstauskunftsdaten
 kl_data_app_wide <- kl_fb_data%>%                           #  Infern      Kennw     Qualdim    Sk Allg
   mutate(`Informativität_arith. Mittel` = FB06_01,          #           # x       #          #      
          `Informativität_Beziehung` = FB03_05,              #           #         #  x       #      
          `Informativität_Boxplot` = FB06_02,                #           # x       #          #      
          `Informativität_Einzelitems` = FB02_06,            #  x        #         #          #      
          `Informativität_Einzelwerte` = FB06_04,            #           # x       #          #      
          `Informativität_Enthusiasmus` = FB03_02,           #           #         #  x       #      
          `Informativität_Freitexte` = FB02_07,              #  x        #         #          #      
          `Informativität_Interaktion` = FB03_04,            #           #         #  x       #      
          `Informativität_ipsativer Vergleich` = FB10_03,    #           #         #          # x   
          `Informativität_Konfidenzintervall` = FB06_03,     #           # x       #          #      
          `Informativität_Lernerfolg` = FB03_01,             #           #         #  x       #      
          `Informativität_Likertskala` = FB10_01,            #           #         #          # x   
          `Informativität_Organisation` = FB03_03,           #           #         #  x       #      
          `Informativität_Qualitätsdimensionen` = FB02_05,   #  x        #         #          #      
          `Informativität_sozialer Vergleich` = FB10_02,     #           #         #          # x
          
          `Interpretation_arith. Mittel` = FB12_01,          #           # x       #          # 
          `Interpretation_Boxplot` = FB12_02,                #           # x       #          #      
          `Interpretation_Einzelitems` = FB02_06,            #  x        #         #          #      
          `Interpretation_Einzelwerte` = FB12_04,            #           # x       #          #      
          `Interpretation_Freitexte` = FB02_07,              #  x        #         #          #      
          `Interpretation_ipsativer Vergleich` = FB11_03,    #           #         #          # x   
          `Interpretation_Konfidenzintervall` = FB12_03,     #           # x       #          #      
          `Interpretation_Likertskala` = FB11_01,            #           #         #          # x   
          `Interpretation_Qualitätsdimensionen` = FB02_05,   #  x        #         #          #      
          `Interpretation_sozialer Vergleich` = FB11_02,     #           #         #          # x
           user = 1:n())

 kl_data_app_long_Inf <- kl_data_app_wide%>%
   gather(VAR, Informativität, `Informativität_arith. Mittel`,
                    `Informativität_Beziehung`,
                    `Informativität_Boxplot`,
                    `Informativität_Einzelitems`,
                    `Informativität_Einzelwerte`,
                    `Informativität_Enthusiasmus`,
                    `Informativität_Freitexte`,
                    `Informativität_Interaktion`,
                    `Informativität_ipsativer Vergleich`,
                    `Informativität_Konfidenzintervall`,
                    `Informativität_Lernerfolg`,
                    `Informativität_Likertskala`,
                    `Informativität_Organisation`,
                    `Informativität_Qualitätsdimensionen`,
                    `Informativität_sozialer Vergleich`)%>%
   dplyr::select(VAR, Informativität, user)%>%
   mutate(value = substr(VAR, 16, 37),
          variable = ifelse(value == "Einzelitems" | value == "Freitexte" | value == "Qualitätsdimensionen", "Inferenzniveau",
                     ifelse(value == "arith. Mittel" | value == "Boxplot" | value == "Einzelwerte" | value == "Konfidenzintervall",  "Kennwerte",
                     ifelse(value == "Lernerfolg" | value == "Interaktion" | value == "Organisation" | 
                              value == "Beziehung" | value == "Enthusiasmus",  "Qualitätsdimension",
                     ifelse(value == "ipsativer Vergleich" | value == "sozialer Vergleich" | value == "Likertskala", "Skalierung Qualitätsdim.", "XXXX")))))%>%
   group_by(user)%>%
   mutate(Informativität_ip = scale_this(Informativität))%>%
   ungroup()%>%
   group_by(variable)%>%
   mutate(Informativität_gm = scale_this(Informativität))%>%
   ungroup()
 
 
 kl_data_app_long_Int <- kl_data_app_wide%>%
   gather(VAR, Interpretationssicherheit, 
                    `Interpretation_arith. Mittel`,
                    `Interpretation_Boxplot`,
                    `Interpretation_Einzelitems`, 
                    `Interpretation_Einzelwerte`,
                    `Interpretation_Freitexte`,
                    `Interpretation_ipsativer Vergleich` ,
                    `Interpretation_Konfidenzintervall`,
                    `Interpretation_Likertskala`,
                    `Interpretation_Qualitätsdimensionen`,
                    `Interpretation_sozialer Vergleich`)%>%
   dplyr::select(VAR, Interpretationssicherheit, user)%>%
   mutate(value = substr(VAR, 16, 37),
          variable = ifelse(value == "Einzelitems" | value == "Freitexte" | value == "Qualitätsdimensionen", "Inferenzniveau",
                     ifelse(value == "arith. Mittel" | value == "Boxplot" | value == "Einzelwerte" | value == "Konfidenzintervall",  "Kennwerte",
                     ifelse(value == "Lernerfolg" | value == "Interaktion" | value == "Organisation" | 
                              value == "Beziehung" | value == "Enthusiasmus",  "Qualitätsdimension",
                     ifelse(value == "ipsativer Vergleich" | value == "sozialer Vergleich" | value == "Likertskala", "Skalierung Qualitätsdim.", "XXXX")))))%>%
   group_by(user)%>%
   mutate(Interpretationssicherheit_ip = scale_this(Interpretationssicherheit))%>%
   ungroup()%>%
   group_by(variable)%>%
   mutate(Interpretationssicherheit_gm = scale_this(Interpretationssicherheit))%>%
   ungroup()%>%
   select(-VAR)
 
 kl_data_app <- full_join(kl_data_app_long_Inf, kl_data_app_long_Int, by = c("user", "value", "variable"))
 
 
 
kl_data_app_long_Inf_leit <- kl_data_app_wide%>%
  select(user, FB13_01, FB13_02, FB13_03, FB13_04)%>%
  gather(VAR, Informativität, -user)%>%
  mutate(variable = "Leitfragen",
         value = ifelse(VAR == "FB13_01", "Überblick",
                        ifelse(VAR == "FB13_02", "ipsativer Vergleich",
                               ifelse(VAR == "FB13_03", "Vergl. zw. eigenen Gruppen",
                                      "sozialer Vergleich"))))%>%
   group_by(user)%>%
   mutate(Informativität_ip = scale_this(Informativität))%>%
   ungroup()%>%
   group_by(variable)%>%
   mutate(Informativität_gm = scale_this(Informativität))%>%
   ungroup()%>%
   select(-VAR)
  
 

kl_data_app_long_Int_leit <- kl_data_app_wide%>%
  select(user, FB14_01, FB14_03, FB14_02, FB14_04)%>%
  gather(VAR, Interpretationssicherheit, -user)%>%
  mutate(variable = "Leitfragen",
         value = ifelse(VAR == "FB14_01", "Überblick",
                        ifelse(VAR == "FB14_03", "ipsativer Vergleich",
                               ifelse(VAR == "FB14_02", "Vergl. zw. eigenen Gruppen",
                                      "sozialer Vergleich"))))%>%
   group_by(user)%>%
   mutate(Interpretationssicherheit_ip = scale_this(Interpretationssicherheit))%>%
   ungroup()%>%
   group_by(variable)%>%
   mutate(Interpretationssicherheit_gm = scale_this(Interpretationssicherheit))%>%
   ungroup()%>%
   select(-VAR)




 
 
kl_data_app <- full_join(kl_data_app_long_Inf, kl_data_app_long_Int, by = c("user", "value", "variable"))
kl_data_app <- full_join(kl_data_app, kl_data_app_long_Inf_leit, by = c("user", "value", "variable", "Informativität", 
                                                                        "Informativität_ip", "Informativität_gm"))

kl_data_app <- full_join(kl_data_app, kl_data_app_long_Int_leit, by = c("user", "value", "variable", "Interpretationssicherheit", 
                                                                        "Interpretationssicherheit_ip", "Interpretationssicherheit_gm"))
  
## Export
readr::write_csv(kl_data_app, "shiny/kl_data_app.csv")
 
```

```{r CFA_SEEQ}
library(lavaan)

# Definition von Printfunktionen

fpf_la <- function(x){  

  fm_tmp <- fitmeasures(x)
                    
  return(sprintf(
          "χ² = %s, _df_ = %s, CFI = %s, TLI = %s, RMSEA = %s, SRMR = %s",
           round(fm_tmp[c("chisq")],3), 
                 fm_tmp[c("df")],
           round(fm_tmp[c("cfi")],3),
           round(fm_tmp[c("tli")],3),
           round(fm_tmp[c("rmsea")],3),
           round(fm_tmp[c("srmr")],3)
             )
       )
}

rpf_bv <- function(x){  
  
   reldat <- sus_fb_data%>%
                    select(starts_with(as.character(x)))%>%
                    select(-ends_with("pc"))
   relinfo <- MBESS::ci.reliability(data.frame(select(reldat, 
                                                      starts_with(as.character(x)))))
                      
  
  return(sprintf(
            "ω = %s, 95%% CI [%s, %s])",
            round(relinfo$est, 2),
            round(relinfo$ci.lower, 2),
            round(relinfo$ci.upper, 2)
            )
         )
}


# CFA

cfa.seeq.mod <- "lern =~ le1 + le2 + le3 + le4
                 enth =~ en1 + en2 + en3 + en4
                 orga =~ or1 + or3 + or3 + or4 
                 grin =~ ci1 + ci2 + ci3 + ci4
                 indb =~ ir1 + ir2 + ir3
                 en1 ~~ en2
                 or3 ~~ or4"

cfa.fit <- cfa(cfa.seeq.mod, data = sus_fb_data, std.lv = T)

# Skalenwerte generieren
sus_fb_data <- sus_fb_data%>%
  mutate(sle = rowMeans(data.frame(le1,le2,le3,le4), na.rm=T),
         sen = rowMeans(data.frame(en1,en2,en3,en4), na.rm=T),
         sor = rowMeans(data.frame(or1,or2,or3,or4), na.rm=T),
         sir = rowMeans(data.frame(ir1,ir2,ir3), na.rm=T),
         sci = rowMeans(data.frame(ci1,ci2,ci3,ci4), na.rm=T))
```


# Design & Stichprobe
* $N_{Level_1}$ = `r nrow(sus_fb_data)` Schüler\*innenfragebögen
* $N_{Level_2}$ = `r length(unique(log_data$user))` Lehrer\*innen = Studierende
* Entwicklung/Adaption eines Instrumentes zur Erfassung der Instruktionsqualität, basierend auf dem Instrument **Students Evaluations of Educational Quality** [SEEQ, @Marsh1982]
     * Fünf Dimensionen: Lernerfolg, Organisation, Enthusiasmus, Interaktion, Beziehung
     * Hohe Konstruktvalidität (CFA: `r fpf_la(cfa.fit)`)
     * Gute Reliabilität auf Level 1 (McDonals Omega) in 4 Dimensionen:
          * Lernerfolg: `r rpf_bv("le")`
          * Enthusiasmus: `r rpf_bv("en")`
          * Organistaion: `r rpf_bv("or")`
          * Gruppeninteraktion: `r rpf_bv("ci")`
          * Individuelle Beziehung: `r rpf_bv("ir")`
     * Sehr gute Reliabilität auf Level 2 (ICC2):
          * Lernerfolg: `r round(psychometric::ICC2.lme(sle, Tutor, sus_fb_data), 3)`
          * Enthusiasmus: `r round(psychometric::ICC2.lme(sen, Tutor, sus_fb_data), 3)`
          * Organistaion: `r round(psychometric::ICC2.lme(sor, Tutor, sus_fb_data), 3)`
          * Gruppeninteraktion: `r round(psychometric::ICC2.lme(sci, Tutor, sus_fb_data), 3)`
          * Individuelle Beziehung: `r round(psychometric::ICC2.lme(sir, Tutor, sus_fb_data), 3)`   
* **Logdaten** der Webapplikation und retrospektive Befragung
     * $N$ = `r nrow(log_data)` Feedbackanforderungen (Logdaten)
     * $N$ = `r nrow(kl_fb_data)` retrospektive Befragungen


# Literatur


